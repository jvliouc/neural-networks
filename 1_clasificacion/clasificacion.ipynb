{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84f79131",
   "metadata": {},
   "source": [
    "# 1. Clasificación\n",
    "## 1.1 elementos básicos\n",
    "### Neurona: unidad fundamental de procesamiento de información \n",
    "### Neural model: \n",
    "#### 1. Synapses o conecciones, cada uno caracterizado con un peso $w_{kj}$, donde k corresponde a la neurona y j al input $x_j$ (considerar un vector de m filas).\n",
    "#### 2. Sumatoria: es la combinación lineal de todos los input ponderado con su respectivo peso.\n",
    "#### 3. Función de activación (Squashing function): limita la amplitud a un rango finito.\n",
    "#### 4. External bias $b_k$: NO ES SESGO estadístico, este afecta antes de la función de activación. Hace que la función no pase por el origen\n",
    "$$\n",
    "u_k=\\sum_{j=1}^{m}{x_jw_{kj}}\n",
    "$$\n",
    "$$\n",
    "y_k=\\phi(u_k+b_k)\n",
    "$$\n",
    "#### El external bias, se puede reemplazar por un input $x_0$=+1 y calcular su peso $b_k$\n",
    "<p align=\"center\">\n",
    "    <img src=\"../1_clasificacion/neural1.png\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "### Disclaimer: La relación entre input y output no tiene porqué ser lineal, un input puede ir a varias neuronas, puede haber feedback, etc. en su momento estudiaré eso de ser necesario.\n",
    "## 2.Regresión lineal\n",
    "#### Variable de interes: respuesta o variable dependiente.\n",
    "#### Regresores: variables independientes cuyo rol es explicar o predecir el comportamiento estadístico de la respuesta.\n",
    "#### Expectational error ($\\epsilon$): para agregar las incertezas en la relacion de dependencia de las variables.\n",
    "#### x: vector de inputs (M en total, u orden del modelo), una sola muestra.\n",
    "#### d: respuesta, asumiremos escalar (no vectorial por simplicidad), una sola muestra.\n",
    "#### w: parametros ajustados-> entorno estocastico estacionario desconocido.\n",
    "#### la función:\n",
    "$$\n",
    "d=\\sum_{j=1}^{M}{w_jx_j}+\\epsilon\n",
    "$$\n",
    "#### vectorialmente:\n",
    "$$\n",
    "d=w^Tx+\\epsilon\n",
    "$$\n",
    "#### Extendiendo el modelo a estadisticas conjuntas:\n",
    "#### X: tiene una matriz de correlación (matriz de correlación del regresor)\n",
    "#### D: tiene una varianza de la respuesta deseada.\n",
    "#### X y D tiene una correlación cruzada.\n",
    "#### se asume que X y D tienen media 0. Matricialmente:\n",
    "$$\n",
    "D=w^TX+\\Epsilon\n",
    "$$\n",
    "### 2.1 Máximo a posteriori (bayesiano)\n",
    "#### Paradigma bayesiano (concepto interesante): Entender la incertidumbre como una probabilidad y actualiza el conocimiento cuando entra nueva información -> nada es verdadero o falso, todo tiene un grado de creencia.\n",
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fb3c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40326188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
